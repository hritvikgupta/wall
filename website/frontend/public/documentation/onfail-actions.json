{
  "id": "onfail-actions",
  "title": "OnFailActions - Failure Handling Strategies",
  "description": "Define what happens when validation fails",
  "content": [
    {
      "type": "text",
      "content": "**OnFailActions** define what happens when validation fails. They are crucial for determining how your application handles invalid LLM responses. Choosing the right OnFailAction is essential for balancing safety, user experience, and system behavior."
    },
    {
      "type": "section",
      "title": "Understanding OnFailActions",
      "subsections": [
        {
          "title": "What are OnFailActions?",
          "type": "text",
          "content": "OnFailActions are strategies that determine the system's response when a validator detects that content doesn't meet the validation criteria.\n\n**Think of it like this**:\n- **Validator**: \"This content is invalid\"\n- **OnFailAction**: \"What should we do about it?\"\n  - Raise an error? (EXCEPTION)\n  - Remove the bad part? (FILTER)\n  - Try again? (REASK)\n  - Fix it? (FIX)\n  - Return nothing? (REFRAIN)\n  - Ignore it? (NOOP)\n\nEach action has different use cases and trade-offs."
        },
        {
          "title": "Why OnFailActions Matter",
          "type": "list",
          "items": [
            "**Safety vs UX**: Balance between blocking unsafe content and providing good user experience",
            "**Error Handling**: Determine how errors are surfaced to users",
            "**Retry Logic**: Control automatic retries and quality improvement",
            "**Content Moderation**: Decide how to handle problematic content",
            "**System Behavior**: Define how your system behaves under failure conditions"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "Available OnFailActions - Detailed Explanation",
      "subsections": [
        {
          "title": "EXCEPTION - Strictest (Raise Error)",
          "type": "text",
          "content": "**EXCEPTION** raises an error immediately when validation fails. This is the strictest action.\n\n**Behavior**:\n- Raises `ValidationError` exception\n- Stops execution\n- No output returned to user\n- Error must be caught and handled\n\n**Use when**:\n- Safety is critical (healthcare, legal, finance)\n- Invalid content must never reach users\n- You want explicit error handling\n\n**Trade-off**: Strict but may block valid content if validator is too aggressive"
        },
        {
          "title": "FILTER - Remove Invalid Content",
          "type": "text",
          "content": "**FILTER** removes invalid content from the response, keeping the valid parts.\n\n**Behavior**:\n- Removes problematic parts\n- Returns cleaned response\n- Continues execution\n- No error raised\n\n**Use when**:\n- Partial content is acceptable\n- Content moderation (remove bad phrases)\n- You want to salvage valid parts\n\n**Trade-off**: May produce incomplete responses"
        },
        {
          "title": "REFRAIN - Return Empty Response",
          "type": "text",
          "content": "**REFRAIN** returns an empty or default response when validation fails.\n\n**Behavior**:\n- Returns empty string or default value\n- No error raised\n- Execution continues\n- User gets no response\n\n**Use when**:\n- No response is safer than a bad response\n- You want to silently fail\n- Default behavior is acceptable\n\n**Trade-off**: User gets no information, but system doesn't crash"
        },
        {
          "title": "REASK - Retry with Feedback",
          "type": "text",
          "content": "**REASK** re-asks the LLM to generate a new response when validation fails, with feedback about what was wrong.\n\n**Behavior**:\n- Provides feedback to LLM about validation failure\n- Re-calls LLM with improved prompt\n- Retries up to `num_reasks` times\n- Returns new response if retry succeeds\n\n**Use when**:\n- Quality improvement is acceptable\n- Retries are acceptable (not too expensive)\n- You want to improve response quality automatically\n\n**Trade-off**: May take longer (multiple LLM calls), but improves quality"
        },
        {
          "title": "FIX - Attempt Automatic Fix",
          "type": "text",
          "content": "**FIX** attempts to programmatically fix invalid content.\n\n**Behavior**:\n- Validator provides a fix (via `fix_value` in FailResult)\n- Fix is applied automatically\n- Fixed content is returned\n- No error raised\n\n**Use when**:\n- Automatic fixes are possible (e.g., add missing disclaimer)\n- Fixes are reliable\n- You want seamless user experience\n\n**Trade-off**: Requires validators to provide fixes, which may not always be possible"
        },
        {
          "title": "FIX_REASK - Try Fix, Then Reask",
          "type": "text",
          "content": "**FIX_REASK** tries to fix first, then reasks if fix fails.\n\n**Behavior**:\n- First attempts automatic fix\n- If fix fails or not available, reasks LLM\n- Best of both worlds\n\n**Use when**:\n- You want to try fixing first (fast)\n- But fall back to reasking if fix doesn't work\n- Balance between speed and quality\n\n**Trade-off**: More complex but more robust"
        },
        {
          "title": "NOOP - Pass Through (No Operation)",
          "type": "text",
          "content": "**NOOP** passes through invalid content without blocking.\n\n**Behavior**:\n- Invalid content is passed through\n- Warning is logged\n- No error raised\n- Execution continues\n\n**Use when**:\n- Logging/monitoring only (don't want to block)\n- Testing validators\n- You want to see what would be blocked\n\n**Trade-off**: Invalid content reaches users (use with caution!)"
        }
      ]
    },
    {
      "type": "section",
      "title": "Complete Usage Examples",
      "subsections": [
        {
          "title": "Example 1: Safety-Critical (EXCEPTION)",
          "type": "code",
          "code": "from wall_library import WallGuard, OnFailAction\n\n# Healthcare application - safety is critical\nguard = WallGuard().use(\n    (HealthcareSafetyValidator, {}, OnFailAction.EXCEPTION)\n)\n\n# If validation fails, exception is raised\ntry:\n    result = guard.validate(\"This is a guaranteed cure!\")\nexcept ValidationError as e:\n    print(f\"❌ Blocked unsafe content: {e}\")\n    # Handle error appropriately (log, notify, etc.)\n    return None  # Don't return unsafe content",
          "input": "Testing EXCEPTION action...",
          "output": "❌ Blocked unsafe content: Response contains restricted term: guaranteed cure"
        },
        {
          "title": "Example 2: Content Moderation (FILTER)",
          "type": "code",
          "code": "# Content moderation - remove bad parts\nguard = WallGuard().use(\n    (ProfanityValidator, {}, OnFailAction.FILTER)\n)\n\n# Invalid content is filtered out\nresult = guard.validate(\"This is great! But this is bad word.\")\n# Result: \"This is great! But this is .\" (bad word removed)\n\nif result.validation_passed:\n    print(f\"Cleaned: {result.validated_output}\")",
          "input": "Testing FILTER action...",
          "output": "Cleaned: This is great! But this is ."
        },
        {
          "title": "Example 3: Quality Improvement (REASK)",
          "type": "code",
          "code": "# Quality improvement - retry if quality is low\nguard = WallGuard(\n    num_reasks=2  # Allow 2 retries\n).use(\n    (QualityValidator, {}, OnFailAction.REASK)\n)\n\n# If quality is low, LLM is re-asked with feedback\nraw, validated, outcome = guard(\n    llm_api=llm_api_call,\n    prompt=\"Tell me about diabetes\"\n)\n\n# Guard automatically:\n# 1. Calls LLM\n# 2. Validates response\n# 3. If fails, provides feedback to LLM\n# 4. Re-calls LLM with feedback\n# 5. Validates new response\n# 6. Returns if passes, or retries again (up to num_reasks)",
          "input": "Testing REASK action...",
          "output": "✅ Response improved through reasking"
        },
        {
          "title": "Example 4: Automatic Fix (FIX)",
          "type": "code",
          "code": "# Validator that provides fixes\n@register_validator(\"add_disclaimer\")\nclass DisclaimerValidator(Validator):\n    def _validate(self, value: str, metadata: dict):\n        if \"consult\" not in value.lower() and \"healthcare\" not in value.lower():\n            # Provide fix: add disclaimer\n            fixed = value + \" [IMPORTANT: Consult a healthcare provider for personalized advice.]\"\n            return FailResult(\n                error_message=\"Missing healthcare disclaimer\",\n                fix_value=fixed,  # This is used by FIX action\n                metadata=metadata\n            )\n        return PassResult(metadata=metadata)\n\n# Use FIX action\nguard = WallGuard().use(\n    (DisclaimerValidator, {}, OnFailAction.FIX)\n)\n\n# If validation fails, fix is automatically applied\nresult = guard.validate(\"Diabetes symptoms include thirst.\")\n# Result: \"Diabetes symptoms include thirst. [IMPORTANT: Consult a healthcare provider for personalized advice.]\"",
          "input": "Testing FIX action...",
          "output": "✅ Content automatically fixed"
        },
        {
          "title": "Example 5: Silent Failure (REFRAIN)",
          "type": "code",
          "code": "# Return empty response if validation fails\nguard = WallGuard().use(\n    (SafetyValidator, {}, OnFailAction.REFRAIN)\n)\n\n# If validation fails, empty string is returned\nresult = guard.validate(\"This contains dangerous content!\")\n\n# result.validated_output is empty string \"\"\n# No error raised\n# User gets no response (safer than unsafe response)",
          "input": "Testing REFRAIN action...",
          "output": "✅ Returned empty response (safer than unsafe)"
        },
        {
          "title": "Example 6: Monitoring Only (NOOP)",
          "type": "code",
          "code": "# Log violations but don't block\nguard = WallGuard().use(\n    (SafetyValidator, {}, OnFailAction.NOOP)\n)\n\n# Invalid content passes through\nresult = guard.validate(\"This contains dangerous content!\")\n\n# result.validated_output contains the invalid content\n# Warning is logged\n# Use for: Testing, monitoring, understanding what would be blocked",
          "input": "Testing NOOP action...",
          "output": "⚠️ Warning logged, content passed through"
        }
      ]
    },
    {
      "type": "section",
      "title": "Choosing the Right OnFailAction",
      "subsections": [
        {
          "title": "Decision Matrix",
          "type": "text",
          "content": "**Safety Critical (Healthcare, Legal, Finance)**:\n- Use **EXCEPTION** for safety validators\n- Block invalid content immediately\n- Explicit error handling\n\n**Content Moderation**:\n- Use **FILTER** to remove bad parts\n- Keep valid content\n- Improve user experience\n\n**Quality Improvement**:\n- Use **REASK** to improve quality\n- Accept retries\n- Better responses\n\n**User Experience**:\n- Use **FIX** or **FIX_REASK** for seamless UX\n- Automatic fixes\n- No user-visible errors\n\n**Monitoring/Testing**:\n- Use **NOOP** to see what would be blocked\n- Log violations\n- Don't block in production"
        },
        {
          "title": "Common Patterns",
          "type": "code",
          "code": "# Pattern 1: Safety First (Healthcare)\nguard = WallGuard()\\\n    .use((SafetyValidator, {}, OnFailAction.EXCEPTION))  # Strict for safety\n    .use((LengthValidator, {}, OnFailAction.REASK))  # Lenient for quality\n\n# Pattern 2: Content Moderation\nguard = WallGuard()\\\n    .use((ProfanityValidator, {}, OnFailAction.FILTER))  # Remove bad words\n    .use((ToxicityValidator, {}, OnFailAction.EXCEPTION))  # Block toxic content\n\n# Pattern 3: Quality Focus\nguard = WallGuard(num_reasks=3)\\\n    .use((QualityValidator, {}, OnFailAction.REASK))  # Retry for quality\n    .use((FormatValidator, {}, OnFailAction.FIX))  # Fix format issues",
          "input": "Creating action patterns...",
          "output": "✅ Action patterns created"
        }
      ]
    },
    {
      "type": "section",
      "title": "Best Practices",
      "subsections": [
        {
          "title": "Recommendations",
          "type": "list",
          "items": [
            "**Use EXCEPTION for safety**: Safety-critical validators should use EXCEPTION",
            "**Use REASK for quality**: Quality validators can use REASK to improve responses",
            "**Use FILTER for moderation**: Content moderation should use FILTER",
            "**Order matters**: Put strict validators (EXCEPTION) first, lenient ones (REASK) last",
            "**Handle exceptions**: Always handle ValidationError when using EXCEPTION",
            "**Set num_reasks**: Configure num_reasks when using REASK (default: 0)",
            "**Monitor actions**: Track which actions are triggered to understand system behavior"
          ]
        },
        {
          "title": "Common Mistakes",
          "type": "list",
          "items": [
            "❌ Using NOOP in production (invalid content reaches users)",
            "❌ Not handling EXCEPTION (application crashes)",
            "❌ Using REASK without num_reasks (no retries happen)",
            "❌ Wrong order (lenient before strict)",
            "❌ Using EXCEPTION for quality (too strict, blocks good content)"
          ]
        }
      ]
    }
  ]
}
