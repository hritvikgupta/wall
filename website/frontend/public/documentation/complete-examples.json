{
  "id": "complete-examples",
  "title": "Complete Examples",
  "description": "End-to-end examples showing all Wall Library features working together",
  "content": [
    {
      "type": "text",
      "content": "Here are complete end-to-end examples showing how to integrate all Wall Library features together. These examples demonstrate real-world usage patterns and best practices."
    },
    {
      "type": "section",
      "title": "Complete Healthcare Application",
      "subsections": [
        {
          "title": "Full Integration Example",
          "type": "code",
          "code": "from wall_library import WallGuard, OnFailAction, WallLogger, LogScope\nfrom wall_library.validator_base import Validator, register_validator\nfrom wall_library.classes.validation.validation_result import PassResult, FailResult\nfrom wall_library.nlp import ContextManager\nfrom wall_library.rag import RAGRetriever, ChromaDBClient, EmbeddingService\nfrom wall_library.scoring import ResponseScorer, ROUGEMetric, BLEUMetric\nfrom wall_library.monitoring import LLMMonitor\nfrom wall_library.visualization import WallVisualizer\nfrom openai import OpenAI\nimport os\nimport tempfile\nimport time\n\n# ========================================\n# 1. SETUP LOGGER (First - logs everything)\n# ========================================\nlog_dir = os.path.join(os.getcwd(), \"logs\")\nos.makedirs(log_dir, exist_ok=True)\nlogger = WallLogger(\n    level=\"INFO\",\n    scopes=[LogScope.ALL.value],\n    output=\"file\",\n    format=\"both\",\n    log_file=os.path.join(log_dir, \"healthcare_app.log\")\n)\n\n# ========================================\n# 2. CREATE VALIDATORS\n# ========================================\n@register_validator(\"healthcare_safety\")\nclass HealthcareSafetyValidator(Validator):\n    def __init__(self, restricted_terms: list = None, **kwargs):\n        super().__init__(require_rc=False, **kwargs)\n        self.restricted_terms = restricted_terms or [\n            \"guaranteed cure\", \"miracle treatment\", \"100% effective\"\n        ]\n    \n    def _validate(self, value: str, metadata: dict):\n        value_lower = value.lower()\n        found = [t for t in self.restricted_terms if t in value_lower]\n        if found:\n            return FailResult(\n                error_message=f\"Restricted terms: {', '.join(found)}\",\n                metadata={**metadata, \"restricted_terms\": found}\n            )\n        return PassResult(metadata=metadata)\n\n@register_validator(\"healthcare_length\")\nclass HealthcareLengthValidator(Validator):\n    def __init__(self, min_length: int = 50, **kwargs):\n        super().__init__(require_rc=False, **kwargs)\n        self.min_length = min_length\n    \n    def _validate(self, value: str, metadata: dict):\n        if len(value) < self.min_length:\n            return FailResult(\n                error_message=f\"Too short: {len(value)} < {self.min_length}\",\n                metadata=metadata\n            )\n        return PassResult(metadata=metadata)\n\n# ========================================\n# 3. CREATE GUARD\n# ========================================\nguard = WallGuard(\n    name=\"healthcare_guard\",\n    num_reasks=2,\n    logger=logger\n)\nguard.use((HealthcareSafetyValidator, {}, OnFailAction.EXCEPTION))\nguard.use((HealthcareLengthValidator, {\"min_length\": 50}, OnFailAction.EXCEPTION))\n\n# ========================================\n# 4. CREATE CONTEXT MANAGER\n# ========================================\ncontext_manager = ContextManager()\ncontext_manager.add_keywords([\"healthcare\", \"medical\", \"doctor\", \"patient\"])\ncontext_manager.add_string_list([\n    \"General health information\",\n    \"Symptom description\",\n    \"Medication information\"\n])\n\n# ========================================\n# 5. SETUP RAG\n# ========================================\ntemp_dir = tempfile.mkdtemp()\nchromadb = ChromaDBClient(\n    collection_name=\"healthcare_kb\",\n    persist_directory=temp_dir\n)\nembedding = EmbeddingService(provider=\"sentence-transformers\")\nrag = RAGRetriever(\n    chromadb_client=chromadb,\n    embedding_service=embedding,\n    top_k=3\n)\nrag.set_logger(logger)\n\n# Add knowledge base\nquestions = [\"What are diabetes symptoms?\", \"How to take medication?\"]\nanswers = [\n    \"Common symptoms include increased thirst and frequent urination.\",\n    \"Take medication as prescribed by your doctor.\"\n]\nchromadb.add_qa_pairs(questions, answers, [{\"domain\": \"healthcare\"} for _ in questions])\n\n# ========================================\n# 6. CREATE SCORER\n# ========================================\nscorer = ResponseScorer()\nscorer.metrics.append(ROUGEMetric())\nscorer.metrics.append(BLEUMetric())\nscorer.set_logger(logger)\n\n# ========================================\n# 7. CREATE MONITOR\n# ========================================\nmonitor = LLMMonitor()\nmonitor.set_logger(logger)\n\n# ========================================\n# 8. CREATE VISUALIZER\n# ========================================\nviz = WallVisualizer(output_dir=\"visualizations\")\n\n# ========================================\n# 9. LLM CLIENT\n# ========================================\nclient = OpenAI(api_key=\"your-api-key\")\n\ndef llm_api_call(prompt: str, **kwargs):\n    response = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        **kwargs\n    )\n    return response.choices[0].message.content\n\n# ========================================\n# 10. COMPLETE PROCESSING FUNCTION\n# ========================================\ndef process_healthcare_query(query: str):\n    \"\"\"Complete end-to-end processing with all features.\"\"\"\n    start_time = time.time()\n    \n    try:\n        # Step 1: Retrieve context from RAG\n        retrieved = rag.retrieve(query, top_k=3)\n        \n        if not retrieved or retrieved[0]['score'] < 0.7:\n            return \"I don't have enough information to answer that question.\"\n        \n        # Step 2: Build prompt with context\n        context = retrieved[0]['document']\n        prompt = f\"Context: {context}\\n\\nQuestion: {query}\"\n        \n        # Step 3: Call LLM with guard (automatic validation)\n        raw, validated, outcome = guard(\n            llm_api=llm_api_call,\n            prompt=prompt\n        )\n        \n        if not outcome.validation_passed:\n            raise ValueError(f\"Validation failed: {outcome.error_messages}\")\n        \n        # Step 4: Check context boundaries\n        if not context_manager.check_context(validated, threshold=0.7):\n            raise ValueError(\"Response outside approved context\")\n        \n        # Step 5: Score response\n        scores = scorer.score(validated, context)\n        aggregated = scorer.aggregate_score(scores)\n        \n        if aggregated < 0.6:\n            print(f\"⚠️ Low quality score: {aggregated:.3f}\")\n        \n        # Step 6: Monitor interaction\n        latency = time.time() - start_time\n        monitor.track_call(\n            input_data=query,\n            output=validated,\n            metadata={\n                \"rag_used\": True,\n                \"rag_score\": retrieved[0]['score'],\n                \"quality_score\": aggregated,\n                \"validation_passed\": True,\n                \"context_passed\": True\n            },\n            latency=latency\n        )\n        \n        # Step 7: Visualize (optional, for analysis)\n        viz.visualize_scores(scores, title=f\"Scores for: {query[:30]}\")\n        \n        # All operations are automatically logged by logger!\n        \n        return validated\n        \n    except Exception as e:\n        # Log error\n        latency = time.time() - start_time\n        monitor.track_call(\n            input_data=query,\n            output=\"\",\n            metadata={\"error\": str(e), \"validation_passed\": False},\n            latency=latency\n        )\n        raise\n\n# ========================================\n# 11. USE THE COMPLETE SYSTEM\n# ========================================\nquery = \"What are diabetes symptoms?\"\nresult = process_healthcare_query(query)\nprint(f\"Result: {result}\")\n\n# Get statistics\nstats = monitor.get_stats()\nprint(f\"\\nStatistics:\")\nprint(f\"Total interactions: {stats['total_interactions']}\")\nprint(f\"Average latency: {stats['metrics']['avg_latency']:.3f}s\")\n\n# All operations are logged in logs/healthcare_app.log\n# Visualizations are saved in visualizations/ directory",
          "input": "Running complete healthcare application...",
          "output": "Result: Common symptoms of diabetes include increased thirst and frequent urination...\n\nStatistics:\nTotal interactions: 1\nAverage latency: 0.450s"
        },
        {
          "title": "What This Example Demonstrates",
          "type": "text",
          "content": "This complete example shows:\n\n1. **Logger Setup**: Automatic logging of all operations\n2. **Custom Validators**: Safety and length validators\n3. **Wall Guard**: Multi-validator validation pipeline\n4. **Context Manager**: Domain boundary enforcement\n5. **RAG Retriever**: Knowledge grounding\n6. **Response Scorer**: Quality assessment\n7. **LLM Monitor**: Performance tracking\n8. **Visualization**: Visual analytics\n9. **Integration**: All components working together\n10. **Error Handling**: Proper error handling and logging\n\nThis is a production-ready pattern you can use in your applications!"
        }
      ]
    },
    {
      "type": "section",
      "title": "Healthcare Domain Example",
      "subsections": [
        {
          "title": "See Full Example",
          "type": "text",
          "content": "See [examples/domain_tests/healthcare_test.py](examples/domain_tests/healthcare_test.py) for a complete healthcare domain example demonstrating all features with detailed comments and explanations."
        }
      ]
    }
  ]
}
