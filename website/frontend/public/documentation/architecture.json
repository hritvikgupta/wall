{
  "id": "architecture",
  "title": "Architecture",
  "description": "Wall Library system architecture and flow",
  "content": [
    {
      "type": "text",
      "content": "Wall Library follows a pipeline architecture where each component processes the LLM interaction sequentially. Understanding the architecture helps you design effective validation pipelines."
    },
    {
      "type": "section",
      "title": "System Architecture Overview",
      "subsections": [
        {
          "title": "Pipeline Architecture",
          "type": "text",
          "content": "Wall Library uses a **sequential pipeline architecture** where data flows through components in order:\n\n1. **Input Processing**: User query enters the system\n2. **Validation**: Input is validated (optional)\n3. **Context Filtering**: Query is checked against context boundaries\n4. **Knowledge Retrieval**: Relevant knowledge is retrieved (RAG, optional)\n5. **LLM Generation**: LLM generates response\n6. **Output Validation**: Response is validated\n7. **Quality Assessment**: Response is scored\n8. **Monitoring**: Interaction is tracked\n9. **Visualization**: Analytics are generated (optional)\n10. **Output**: Validated, safe response is returned\n\nEach component can be used independently or combined for maximum protection."
        },
        {
          "title": "Component Responsibilities",
          "type": "text",
          "content": "Each component has a specific responsibility:\n\n- **Wall Guard**: Validates inputs and outputs using validators\n- **Context Manager**: Ensures responses stay in approved domain\n- **RAG Retriever**: Grounds responses in verified knowledge\n- **Response Scorer**: Evaluates response quality\n- **LLM Monitor**: Tracks all interactions\n- **Wall Logger**: Logs all operations\n- **Visualization**: Creates visual analytics"
        }
      ]
    },
    {
      "type": "section",
      "title": "Complete Architecture Flow",
      "subsections": [
        {
          "title": "Detailed Pipeline",
          "type": "code",
          "code": "User Query\n    ↓\n[Input Validation] ← Wall Guard validates user input (optional)\n    ↓\n[Context Check] ← Context Manager checks if query is in approved domain\n    ↓\n[RAG Retrieval] ← RAG Retriever gets relevant knowledge (optional)\n    ↓\n[Prompt Building] ← Build prompt with context\n    ↓\n[LLM] ← LLM generates response\n    ↓\n[Output Validation] ← Wall Guard validates LLM response\n    ↓\n[Context Check] ← Context Manager checks if response is in approved domain\n    ↓\n[Scoring] ← Response Scorer evaluates quality\n    ↓\n[Monitoring] ← LLM Monitor tracks interaction\n    ↓\n[Logging] ← Wall Logger logs all operations (automatic)\n    ↓\n[Visualization] ← Generate analytics (optional)\n    ↓\nValidated Safe Response",
          "input": "",
          "output": ""
        },
        {
          "title": "Understanding the Flow",
          "type": "text",
          "content": "**Input Stage**:\n- User query enters system\n- Optional: Validate input (prevent prompt injection)\n- Optional: Check if query is in approved domain\n\n**Retrieval Stage** (if using RAG):\n- Retrieve relevant knowledge from vector database\n- Build prompt with retrieved context\n- This grounds the response in verified knowledge\n\n**Generation Stage**:\n- LLM generates response based on prompt\n- Response may include retrieved context\n\n**Validation Stage**:\n- Validate response structure (schema)\n- Validate response safety (validators)\n- Check context boundaries\n- Score quality\n\n**Observability Stage**:\n- Monitor interaction (track for analytics)\n- Log all operations (for debugging/compliance)\n- Generate visualizations (for analysis)\n\n**Output Stage**:\n- Return validated, safe response\n- Or raise error if validation failed"
        }
      ]
    },
    {
      "type": "section",
      "title": "Component Overview",
      "subsections": [
        {
          "title": "Core Components",
          "type": "list",
          "items": [
            "**Wall Guard**: Multi-validator validation engine - validates inputs and outputs using chained validators",
            "**Context Manager**: NLP-based context filtering - ensures responses stay within approved domain boundaries using keyword matching and semantic similarity",
            "**RAG Retriever**: Knowledge grounding - retrieves relevant knowledge from vector database to ground responses in verified information",
            "**Response Scorer**: Quality metrics evaluation - evaluates response quality using multiple metrics (ROUGE, BLEU, cosine similarity, etc.)",
            "**LLM Monitor**: Tracking and analytics - tracks all LLM interactions for monitoring, performance analysis, and compliance",
            "**Wall Logger**: Comprehensive logging - automatically logs all operations (validation, RAG, scoring, LLM calls) for debugging and compliance",
            "**Visualization**: Visual analytics tools - creates visual representations (3D graphs, word clouds, dashboards) for analysis and presentation"
          ]
        },
        {
          "title": "Supporting Components",
          "type": "list",
          "items": [
            "**Validators**: Reusable validation rules - define what to check (safety, length, format, etc.)",
            "**OnFailActions**: Failure handling strategies - define what happens when validation fails",
            "**Schema Systems**: Structured output validation - ensure outputs match expected structure (Pydantic, RAIL, JSON Schema)",
            "**Framework Wrappers**: Framework integration - make guards usable in LangChain, LangGraph, etc.",
            "**Execution Modes**: Different execution styles - synchronous, async, streaming, async streaming"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "Data Flow",
      "subsections": [
        {
          "title": "Request Flow",
          "type": "text",
          "content": "**1. User Query** → String input\n\n**2. Input Validation** (optional) → Validated query or error\n\n**3. Context Check** (optional) → Query approved or rejected\n\n**4. RAG Retrieval** (optional) → Retrieved contexts with scores\n\n**5. Prompt Building** → Prompt string with context\n\n**6. LLM Generation** → Raw LLM response\n\n**7. Output Validation** → ValidationOutcome (pass/fail, validated output, errors)\n\n**8. Context Check** → Boolean (in context or not)\n\n**9. Scoring** → Dictionary of scores\n\n**10. Monitoring** → Tracked interaction\n\n**11. Logging** → Log entries (automatic)\n\n**12. Visualization** (optional) → Image/HTML files\n\n**13. Final Output** → Validated, safe response"
        },
        {
          "title": "Error Flow",
          "type": "text",
          "content": "When validation fails:\n\n1. **Validator detects issue** → Returns FailResult\n2. **OnFailAction determines response**:\n   - EXCEPTION → Raises error, stops pipeline\n   - FILTER → Removes invalid content, continues\n   - REASK → Retries with feedback, continues\n   - FIX → Attempts fix, continues\n   - REFRAIN → Returns empty, stops\n   - NOOP → Passes through, continues\n3. **Error logged** (if logger is set)\n4. **Error tracked** (if monitor is set)\n5. **Error returned** to caller"
        }
      ]
    },
    {
      "type": "section",
      "title": "Design Principles",
      "subsections": [
        {
          "title": "Key Principles",
          "type": "list",
          "items": [
            "**Modularity**: Each component is independent and can be used separately",
            "**Composability**: Components can be combined for maximum protection",
            "**Flexibility**: Use only what you need, skip optional components",
            "**Observability**: Built-in logging and monitoring for production",
            "**Extensibility**: Easy to add custom validators and metrics",
            "**Performance**: Efficient execution, supports async and streaming"
          ]
        },
        {
          "title": "Integration Patterns",
          "type": "text",
          "content": "**Pattern 1: Minimal**\n- Wall Guard only\n- Fast, simple validation\n- Use for: Basic safety checks\n\n**Pattern 2: Standard**\n- Wall Guard + Context Manager\n- Domain filtering + validation\n- Use for: Domain-specific applications\n\n**Pattern 3: Enhanced**\n- Wall Guard + Context Manager + RAG\n- Knowledge grounding + validation\n- Use for: Applications requiring verified knowledge\n\n**Pattern 4: Complete**\n- All components (Guard + Context + RAG + Scoring + Monitoring + Logging)\n- Maximum protection and observability\n- Use for: Production applications"
        }
      ]
    },
    {
      "type": "section",
      "title": "Best Practices",
      "subsections": [
        {
          "title": "Architecture Recommendations",
          "type": "list",
          "items": [
            "**Start simple**: Begin with Wall Guard, add components as needed",
            "**Use appropriate components**: Don't use components you don't need",
            "**Set up logging early**: Enable logging from the start for debugging",
            "**Monitor in production**: Always use LLM Monitor in production",
            "**Validate at key points**: Validate both input and output",
            "**Use RAG for accuracy**: Use RAG when you need verified knowledge",
            "**Score for quality**: Use scoring to track and improve quality"
          ]
        }
      ]
    }
  ]
}
